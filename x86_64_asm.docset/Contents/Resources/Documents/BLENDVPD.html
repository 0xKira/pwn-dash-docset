<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" xmlns:svg="http://www.w3.org/2000/svg" xmlns:x86="http://www.felixcloutier.com/x86"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><link rel="stylesheet" type="text/css" href="style.css"/><a class="dashingAutolink" name="autolink-30"></a><a class="dashAnchor" name="//apple_ref/cpp/Instruction/BLENDVPD"></a><title>BLENDVPD</title></head><body><header><nav><ul><li><a href="index.html">Index</a></li><li>May 2019</li></ul></nav></header><h1>BLENDVPD
		&mdash; Variable Blend Packed Double Precision Floating-Point Values</h1>

<table>
<tbody><tr>
<th>Opcode/Instruction</th>
<th>Op/En</th>
<th>64/32-bit Mode</th>
<th>CPUID Feature Flag</th>
<th>Description</th></tr>
<tr>
<td>66 0F 38 15 /r BLENDVPD xmm1, xmm2/m128 , &lt;XMM0&gt;</td>
<td>RM0</td>
<td>V/V</td>
<td>SSE4_1</td>
<td>Select packed DP FP values from <em>xmm1</em> and <em>xmm2</em> from mask specified in <em>XMM0</em> and store the values in <em>xmm1</em>.</td></tr>
<tr>
<td>VEX.128.66.0F3A.W0 4B /r /is4 VBLENDVPD xmm1, xmm2, xmm3/m128, xmm4</td>
<td>RVMR</td>
<td>V/V</td>
<td>AVX</td>
<td>Conditionally copy double-precision floating-point values from xmm2 or xmm3/m128 to xmm1, based on mask bits in the mask operand, xmm4.</td></tr>
<tr>
<td>VEX.256.66.0F3A.W0 4B /r /is4 VBLENDVPD ymm1, ymm2, ymm3/m256, ymm4</td>
<td>RVMR</td>
<td>V/V</td>
<td>AVX</td>
<td>Conditionally copy double-precision floating-point values from ymm2 or ymm3/m256 to ymm1, based on mask bits in the mask operand, ymm4.</td></tr></tbody></table>
<h2 id="instruction-operand-encoding">Instruction Operand Encoding<a class="anchor" href="BLENDVPD.html#instruction-operand-encoding">
			&para;
		</a></h2>
<table>
<tbody><tr>
<td>Op/En</td>
<td>Operand 1</td>
<td>Operand 2</td>
<td>Operand 3</td>
<td>Operand 4</td></tr>
<tr>
<td>RM0</td>
<td>ModRM:reg (r, w)</td>
<td>ModRM:r/m (r)</td>
<td>implicit XMM0</td>
<td>NA</td></tr>
<tr>
<td>RVMR</td>
<td>ModRM:reg (w)</td>
<td>VEX.vvvv (r)</td>
<td>ModRM:r/m (r)</td>
<td>imm8[7:4]</td></tr></tbody></table>
<h2 id="description">Description<a class="anchor" href="BLENDVPD.html#description">
			&para;
		</a></h2>
<p>Conditionally copy each quadword data element of double-precision floating-point value from the second source operand and the first source operand depending on mask bits defined in the mask register operand. The mask bits are the most significant bit in each quadword element of the mask register.</p>
<p>Each quadword element of the destination operand is copied from:</p>
<ul>
<li>the corresponding quadword element in the second source operand, if a mask bit is &ldquo;1&rdquo;; or</li>
<li>the corresponding quadword element in the first source operand, if a mask bit is &ldquo;0&rdquo;</li></ul>
<p>The register assignment of the implicit mask operand for BLENDVPD is defined to be the architectural register XMM0.</p>
<p>128-bit Legacy SSE version: The first source operand and the destination operand is the same. Bits (MAXVL-1:128) of the corresponding YMM destination register remain unchanged. The mask register operand is implicitly defined to be the architectural register XMM0. An attempt to execute BLENDVPD with a VEX prefix will cause #UD.</p>
<p>VEX.128 encoded version: The first source operand and the destination operand are XMM registers. The second source operand is an XMM register or 128-bit memory location. The mask operand is the third source register, and encoded in bits[7:4] of the immediate byte(imm8). The bits[3:0] of imm8 are ignored. In 32-bit mode, imm8[7] is ignored. The upper bits (MAXVL-1:128) of the corresponding YMM register (destination register) are zeroed. VEX.W must be 0, otherwise, the instruction will #UD.</p>
<p>VEX.256 encoded version: The first source operand and destination operand are YMM registers. The second source operand can be a YMM register or a 256-bit memory location. The mask operand is the third source register, and encoded in bits[7:4] of the immediate byte(imm8). The bits[3:0] of imm8 are ignored. In 32-bit mode, imm8[7] is ignored. VEX.W must be 0, otherwise, the instruction will #UD.</p>
<p>VBLENDVPD permits the mask to be any XMM or YMM register. In contrast, BLENDVPD treats XMM0 implicitly as the mask and do not support non-destructive destination operation.</p>
<h2 id="operation">Operation<a class="anchor" href="BLENDVPD.html#operation">
			&para;
		</a></h2>
<h3 id="blendvpd--128-bit-legacy-sse-version-">BLENDVPD (128-bit Legacy SSE version)<a class="anchor" href="BLENDVPD.html#blendvpd--128-bit-legacy-sse-version-">
			&para;
		</a></h3>
<pre>MASK &larr; XMM0
IF (MASK[63] = 0) THEN DEST[63:0]&larr;DEST[63:0]
    ELSE DEST [63:0]&larr;SRC[63:0] FI
IF (MASK[127] = 0) THEN DEST[127:64]&larr;DEST[127:64]
    ELSE DEST [127:64]&larr;SRC[127:64] FI
DEST[MAXVL-1:128] (Unmodified)
</pre>
<h3 id="vblendvpd--vex-128-encoded-version-">VBLENDVPD (VEX.128 encoded version)<a class="anchor" href="BLENDVPD.html#vblendvpd--vex-128-encoded-version-">
			&para;
		</a></h3>
<pre>MASK &larr; SRC3
IF (MASK[63] = 0) THEN DEST[63:0]&larr;SRC1[63:0]
    ELSE DEST [63:0]&larr;SRC2[63:0] FI
IF (MASK[127] = 0) THEN DEST[127:64]&larr;SRC1[127:64]
    ELSE DEST [127:64]&larr;SRC2[127:64] FI
DEST[MAXVL-1:128] &larr; 0
</pre>
<h3 id="vblendvpd--vex-256-encoded-version-">VBLENDVPD (VEX.256 encoded version)<a class="anchor" href="BLENDVPD.html#vblendvpd--vex-256-encoded-version-">
			&para;
		</a></h3>
<pre>MASK &larr; SRC3
IF (MASK[63] = 0) THEN DEST[63:0]&larr;SRC1[63:0]
    ELSE DEST [63:0]&larr;SRC2[63:0] FI
IF (MASK[127] = 0) THEN DEST[127:64]&larr;SRC1[127:64]
    ELSE DEST [127:64]&larr;SRC2[127:64] FI
IF (MASK[191] = 0) THEN DEST[191:128]&larr;SRC1[191:128]
    ELSE DEST [191:128]&larr;SRC2[191:128] FI
IF (MASK[255] = 0) THEN DEST[255:192]&larr;SRC1[255:192]
    ELSE DEST [255:192]&larr;SRC2[255:192] FI
</pre>
<h2 id="intel-c-c++-compiler-intrinsic-equivalent">Intel C/C++ Compiler Intrinsic Equivalent<a class="anchor" href="BLENDVPD.html#intel-c-c++-compiler-intrinsic-equivalent">
			&para;
		</a></h2>
<pre>BLENDVPD: __m128d _mm_blendv_pd(__m128d v1, __m128d v2, __m128d v3);
</pre>
<pre>VBLENDVPD: __m128 _mm_blendv_pd (__m128d a, __m128d b, __m128d mask);
</pre>
<pre>VBLENDVPD: __m256 _mm256_blendv_pd (__m256d a, __m256d b, __m256d mask);
</pre>
<h2 class="exceptions" id="simd-floating-point-exceptions">SIMD Floating-Point Exceptions<a class="anchor" href="BLENDVPD.html#simd-floating-point-exceptions">
			&para;
		</a></h2>
<p>None</p>
<h2 class="exceptions" id="other-exceptions">Other Exceptions<a class="anchor" href="BLENDVPD.html#other-exceptions">
			&para;
		</a></h2>
<p>See Exceptions Type 4; additionally</p>
<table>
<tbody><tr>
<td>#UD</td>
<td>If VEX.W = 1.</td></tr></tbody></table><footer><p>
		This UNOFFICIAL, mechanically-separated, non-verified reference is provided for convenience, but it may be
		inc<span style="opacity: 0.2">omp</span>lete or b<sub>r</sub>oke<sub>n</sub> in various obvious or non-obvious
		ways. Refer to <a href="https://software.intel.com/sites/default/files/managed/39/c5/325462-sdm-vol-1-2abcd-3abcd.pdf">Intel&reg; 64 and IA-32 Architectures Software Developer&rsquo;s Manual</a> for anything serious.
	</p></footer>
</body></html>