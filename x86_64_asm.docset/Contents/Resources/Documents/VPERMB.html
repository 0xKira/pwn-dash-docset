<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" xmlns:svg="http://www.w3.org/2000/svg" xmlns:x86="http://www.felixcloutier.com/x86"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><link rel="stylesheet" type="text/css" href="style.css"/><a class="dashingAutolink" name="autolink-581"></a><a class="dashAnchor" name="//apple_ref/cpp/Instruction/VPERMB"></a><title>VPERMB</title></head><body><header><nav><ul><li><a href="index.html">Index</a></li><li>November 2018</li></ul></nav></header><h1>VPERMB
		&mdash; Permute Packed Bytes Elements</h1>

<table>
<tbody><tr>
<th>Opcode/Instruction</th>
<th>Op/En</th>
<th>64/32 bit Mode Support</th>
<th>CPUID Feature Flag</th>
<th>Description</th></tr>
<tr>
<td>EVEX.128.66.0F38.W0 8D /r VPERMB xmm1 {k1}{z}, xmm2, xmm3/m128</td>
<td>A</td>
<td>V/V</td>
<td>AVX512VL AVX512_VBMI</td>
<td>Permute bytes in xmm3/m128 using byte indexes in xmm2 and store the result in xmm1 using writemask k1.</td></tr>
<tr>
<td>EVEX.256.66.0F38.W0 8D /r VPERMB ymm1 {k1}{z}, ymm2, ymm3/m256</td>
<td>A</td>
<td>V/V</td>
<td>AVX512VL AVX512_VBMI</td>
<td>Permute bytes in ymm3/m256 using byte indexes in ymm2 and store the result in ymm1 using writemask k1.</td></tr>
<tr>
<td>EVEX.512.66.0F38.W0 8D /r VPERMB zmm1 {k1}{z}, zmm2, zmm3/m512</td>
<td>A</td>
<td>V/V</td>
<td>AVX512_VBMI</td>
<td>Permute bytes in zmm3/m512 using byte indexes in zmm2 and store the result in zmm1 using writemask k1.</td></tr></tbody></table>
<h2 id="instruction-operand-encoding">Instruction Operand Encoding<a class="anchor" href="VPERMB.html#instruction-operand-encoding">
			&para;
		</a></h2>
<table>
<tbody><tr>
<td>Op/En</td>
<td>Tuple Type</td>
<td>Operand 1</td>
<td>Operand 2</td>
<td>Operand 3</td>
<td>Operand 4</td></tr>
<tr>
<td>A</td>
<td>Full Mem</td>
<td>ModRM:reg (w)</td>
<td>EVEX.vvvv (r)</td>
<td>ModRM:r/m (r)</td>
<td>NA</td></tr></tbody></table>
<h3 id="description">Description<a class="anchor" href="VPERMB.html#description">
			&para;
		</a></h3>
<p>Copies bytes from the second source operand (the third operand) to the destination operand (the first operand) according to the byte indices in the first source operand (the second operand). Note that this instruction permits a byte in the source operand to be copied to more than one location in the destination operand.</p>
<p>Only the low 6(EVEX.512)/5(EVEX.256)/4(EVEX.128) bits of each byte index is used to select the location of the source byte from the second source operand.</p>
<p>The first source operand is a ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit memory location. The destination operand is a ZMM/YMM/XMM register updated at byte granularity by the writemask k1.</p>
<h3 id="operation">Operation<a class="anchor" href="VPERMB.html#operation">
			&para;
		</a></h3>
<h4 id="vpermb--evex-encoded-versions-">VPERMB (EVEX encoded versions)<a class="anchor" href="VPERMB.html#vpermb--evex-encoded-versions-">
			&para;
		</a></h4>
<pre>(KL, VL) = (16, 128), (32, 256), (64, 512)
IF VL = 128:
    n &larr; 3;
ELSE IF VL = 256:
    n &larr; 4;
ELSE IF VL = 512:
    n &larr; 5;
FI;
FOR j &larr; 0 TO KL-1:
    id &larr; SRC1[j*8 + n : j*8] ; // location of the source byte
    IF k1[j] OR *no writemask* THEN
        DEST[j*8 + 7: j*8] &larr; SRC2[id*8 +7: id*8];
    ELSE IF zeroing-masking THEN
        DEST[j*8 + 7: j*8] &larr; 0;
    *ELSE
        DEST[j*8 + 7: j*8] remains unchanged*
    FI
ENDFOR
DEST[MAX_VL-1:VL] &larr; 0;
</pre>
<h3 id="intel-c-c++-compiler-intrinsic-equivalent">Intel C/C++ Compiler Intrinsic Equivalent<a class="anchor" href="VPERMB.html#intel-c-c++-compiler-intrinsic-equivalent">
			&para;
		</a></h3>
<pre>VPERMB __m512i _mm512_permutexvar_epi8( __m512i idx, __m512i a);
</pre>
<pre>VPERMB __m512i _mm512_mask_permutexvar_epi8(__m512i s, __mmask64 k, __m512i idx, __m512i a);
</pre>
<pre>VPERMB __m512i _mm512_maskz_permutexvar_epi8( __mmask64 k, __m512i idx, __m512i a);
</pre>
<pre>VPERMB __m256i _mm256_permutexvar_epi8( __m256i idx, __m256i a);
</pre>
<pre>VPERMB __m256i _mm256_mask_permutexvar_epi8(__m256i s, __mmask32 k, __m256i idx, __m256i a);
</pre>
<pre>VPERMB __m256i _mm256_maskz_permutexvar_epi8( __mmask32 k, __m256i idx, __m256i a);
</pre>
<pre>VPERMB __m128i _mm_permutexvar_epi8( __m128i idx, __m128i a);
</pre>
<pre>VPERMB __m128i _mm_mask_permutexvar_epi8(__m128i s, __mmask16 k, __m128i idx, __m128i a);
</pre>
<pre>VPERMB __m128i _mm_maskz_permutexvar_epi8( __mmask16 k, __m128i idx, __m128i a);
</pre>
<h3 class="exceptions" id="simd-floating-point-exceptions">SIMD Floating-Point Exceptions<a class="anchor" href="VPERMB.html#simd-floating-point-exceptions">
			&para;
		</a></h3>
<p>None.</p>
<h3 class="exceptions" id="other-exceptions">Other Exceptions<a class="anchor" href="VPERMB.html#other-exceptions">
			&para;
		</a></h3>
<p>See Exceptions Type E4NF.nb.</p><footer><p>
		This UNOFFICIAL, mechanically-separated, non-verified reference is provided for convenience, but it may be
		inc<span style="opacity: 0.2">omp</span>lete or b<sub>r</sub>oke<sub>n</sub> in various obvious or non-obvious
		ways. Refer to <a href="https://software.intel.com/sites/default/files/managed/39/c5/325462-sdm-vol-1-2abcd-3abcd.pdf">Intel&reg; 64 and IA-32 Architectures Software Developer&rsquo;s Manual</a> for anything serious.
	</p></footer>
</body></html>